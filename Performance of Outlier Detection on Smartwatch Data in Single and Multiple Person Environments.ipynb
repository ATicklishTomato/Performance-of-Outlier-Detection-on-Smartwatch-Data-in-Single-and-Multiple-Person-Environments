{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308ff4e4",
   "metadata": {},
   "source": [
    "# Performance of Outlier Detection on Smartwatch Data in Single and Multiple Person Environments\n",
    "## An analysis and comparison of different outlier and anomaly detection methods when applied to heart rate and step count data from consumer-grade wearables\n",
    "Luuk Wubben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as lib\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import itertools\n",
    "from typing import Iterable\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from kneebow.rotor import Rotor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings(action='once')\n",
    "\n",
    "#in case you don't have some of the above libraries, comment them out, then use the below lines to download them first.\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAL VARIABLES. ADVISE TO OVERRIDE PER ALGORITHM PER ENVIRONMENT BELOW.\n",
    "#Data Preprocessing Variables\n",
    "data_sel = {\n",
    "    'hr': True,\n",
    "    'norm_hr': True,\n",
    "    'steps': True,\n",
    "    'norm_steps': True\n",
    "}\n",
    "features = {\n",
    "    'count': False,\n",
    "    'mean': True,\n",
    "    'std': True,\n",
    "    'min': True,\n",
    "    'percentiles': [0.25, 0.5, 0.75],\n",
    "    'max': True,\n",
    "    'n_th_step': True,\n",
    "    'mfcc': True\n",
    "}\n",
    "n_th_step_moment = 6\n",
    "using_feat = [x for x, y in features.items() if (type(y) == bool and y) or (type(y) == list and len(y) > 0)]\n",
    "window = {\n",
    "    'size': 3600,     #in seconds\n",
    "    'stride': 900       #in seconds\n",
    "}\n",
    "subjects_path = './path/to/subject/data'\n",
    "subject_directory_files = os.listdir(subjects_path)\n",
    "subjects = []\n",
    "#Append '.pkl' if not included. Pickled files only.\n",
    "# Data should be pickled Pandas DataFrames per subject consisting of timeseries data with columns 'time',\n",
    "# 'hr' and 'steps'\n",
    "subjects = [(subjects_path + x) if x.endswith('.pkl') else (subjects_path + (x + '.pkl')) for x in subjects]\n",
    "combine_subject_dataframes = True\n",
    "\n",
    "#the variable below dictates how many data points from different subjects should be mixed in, as a value between 0 and 1.\n",
    "#e.g. a value of 0.05 will take |subject_1_data|*0.05 data entries from a random person in the subjects list and insert\n",
    "#them into the dataframe of subject_1. 0 is no mixing, 1 is adding a whole extra dataframe\n",
    "mixing = 0.1\n",
    "\n",
    "#Select for single person and multiple person whether outliers should be within subject/group,\n",
    "#or between subject/group and a set of outliers from another random subject.\n",
    "outlier_selection = {\n",
    "    'within_subject': True,\n",
    "    'between_subjects': False,\n",
    "    'within_group': False,\n",
    "    'between_group_and_individual': True\n",
    "}\n",
    "\n",
    "#Validate outlier selection\n",
    "assert not (outlier_selection['within_subject'] and outlier_selection['between_subjects']), \\\n",
    "\"Cannot do both within and between subjects for a single person environment\"\n",
    "\n",
    "assert not (outlier_selection['within_group'] and outlier_selection['between_group_and_individual']), \\\n",
    "\"Cannot do both within group and between group and subject for a multiple person environment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acca50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_creation():\n",
    "    \"\"\"Create sliding windows based on parameters in setup block above.\"\"\"\n",
    "    #Load data\n",
    "    subject_data = []\n",
    "    for filename in subjects:\n",
    "        with open(filename, 'rb') as file:\n",
    "            unpickled = pickle.load(file)\n",
    "            if len(unpickled.index) < 100*(window['size'] - window['stride']):\n",
    "                raise Exception(\"subject must have at least enough data for 100 windows, can only make \" + \\\n",
    "                                f\"{len(unpickled.index)/(window['size'] - window['stride'])} for subject {filename}.\")\n",
    "            unpickled = filter_data(unpickled, filename)\n",
    "            subject_data.append(unpickled)\n",
    "    \n",
    "    #Create windows of data\n",
    "    windowed_subject_data = []\n",
    "    for subject in subject_data:\n",
    "        windowed_subject_data.append(create_windows(subject))\n",
    "    \n",
    "    #Create mix data and add to windowed subject data\n",
    "    if mixing > 0:\n",
    "        #create set of files not yet used\n",
    "        potential_mix_subjects = list(set([subjects_path + x for x in subject_directory_files]) - set(subjects))\n",
    "        #pick a random one\n",
    "        mix_subject = random.choice(potential_mix_subjects)\n",
    "        #extract data and window it\n",
    "        with open(mix_subject, 'rb') as file:\n",
    "            unpickled = pickle.load(file)\n",
    "            unpickled = filter_data(unpickled, \"MIX: \" + mix_subject)\n",
    "            mix_data_window = create_windows(unpickled)\n",
    "            mix_data = []\n",
    "            #create random mix sample for every subject data set based on desired fraction \n",
    "            #or entire mix_data if |mix_data| < mixing*|windowed_subject|\n",
    "            for subject in windowed_subject_data:\n",
    "                mix_data.append(mix_data_window.sample(n=min(len(mix_data_window.values), \\\n",
    "                                                              int(mixing*len(subject.values)))))\n",
    "    \n",
    "    if combine_subject_dataframes:\n",
    "        return pd.concat(windowed_subject_data, ignore_index=True), mix_data\n",
    "    else:\n",
    "        return windowed_subject_data, mix_data\n",
    "    \n",
    "def normalize(window):\n",
    "    mean = window.mean(skipna=True)\n",
    "    std = window.std(ddof=0, skipna=True)\n",
    "    window = (window - mean)/std\n",
    "    return window\n",
    "\n",
    "def filter_data(data, filename):\n",
    "    #Interpolate missing data\n",
    "    data['hr'] = data['hr'].ffill().bfill()\n",
    "    data['steps'] = data['steps'].ffill().bfill()\n",
    "    data['steps'] = data['steps'].sparse.to_dense()\n",
    "    \n",
    "    #Record mean & std\n",
    "    print(f\"{filename} - Mean hr: {data['hr'].mean(skipna=True)} - STD hr: {data['hr'].std(ddof=0, skipna=True)}\")\n",
    "    print(f\"{filename} - Mean steps: {data['steps'].mean(skipna=True)} - STD steps: {data['steps'].std(ddof=0, skipna=True)}\")\n",
    "    \n",
    "    #Normalize if needed\n",
    "    if data_sel['norm_hr']:\n",
    "        data['hr'] = normalize(data['hr'])\n",
    "    if data_sel['norm_steps']:\n",
    "        data['steps'] = normalize(data['steps'])\n",
    "        \n",
    "    data[\"elapsed_time\"] = (data[\"time\"] - data[\"time\"][0]).dt.total_seconds()\n",
    "    \n",
    "    #Select desired data\n",
    "    if data_sel['hr'] and data_sel['steps']:\n",
    "        return data\n",
    "    elif data_sel['hr']:\n",
    "        return data.drop(['steps'], axis=1)\n",
    "    elif data_sel['steps']:\n",
    "        return data.drop(['hr'], axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"Can't make windows with no data, dummy\")\n",
    "\n",
    "def describe(window, start_time, end_time, prefix = \"\"):\n",
    "    description = {}\n",
    "    if features['count']:\n",
    "        description[prefix + 'count'] = len(window)\n",
    "    if features['mean']:\n",
    "        description[prefix + 'mean'] = window.mean(skipna=True)\n",
    "    if features['std']:\n",
    "        description[prefix + 'std'] = window.std(ddof=0, skipna=True)\n",
    "    if features['min']:\n",
    "        description[prefix + 'min'] = window.min()\n",
    "    if len(features['percentiles']) > 0:\n",
    "        for quant in features['percentiles']:\n",
    "            description[prefix + str(quant)] = window.quantile(quant)\n",
    "    if features['max']:\n",
    "        description[prefix + 'max'] = window.max()\n",
    "    if features['n_th_step']:\n",
    "        description[prefix + 'n_th_step'] = sc.stats.moment(window, moment = n_th_step_moment, nan_policy='omit')\n",
    "    if features['mfcc']:\n",
    "        time = (end_time - start_time)\n",
    "        sr = len(window.values)/time\n",
    "        res = lib.feature.mfcc(y=window.to_numpy(), sr=sr, n_mfcc=1, n_mels=1)[0]\n",
    "        description[prefix + 'mfcc'] = np.mean(res)\n",
    "\n",
    "    return description\n",
    "\n",
    "def create_windows(subject_data):\n",
    "    index = 0\n",
    "    data = []\n",
    "    window_end_index = index + window['size']\n",
    "    new_start_index = window_end_index - window['stride']\n",
    "    while new_start_index < subject_data['elapsed_time'].values[-1]:\n",
    "#         print(f\"{new_start_index}, {subject_data['elapsed_time'].values[-1]}\")\n",
    "        #Create, describe, and store windows\n",
    "        new_window = subject_data[subject_data['elapsed_time'].between(index, window_end_index, inclusive='left')]\n",
    "        if len(new_window.values) == 0:\n",
    "            index = new_start_index\n",
    "            window_end_index = index + window['size']\n",
    "            new_start_index = window_end_index - window['stride']\n",
    "            continue\n",
    "        new_row = {}\n",
    "        if data_sel['hr'] and data_sel['steps']:\n",
    "            hr_window = new_window['hr']\n",
    "            new_row.update(describe(hr_window, index, window_end_index,\"hr_\"))\n",
    "            steps_window = new_window['steps']\n",
    "            new_row.update(describe(steps_window, index, window_end_index,\"steps_\"))\n",
    "        elif data_sel['hr']:\n",
    "            hr_window = new_window['hr']\n",
    "            new_row.update(describe(hr_window, index, window_end_index,\"hr_\"))\n",
    "        elif data_sel['steps']:\n",
    "            steps_window = new_window['steps']\n",
    "            new_row.update(describe(steps_window, index, window_end_index,\"steps_\"))\n",
    "            \n",
    "        data.append(pd.Series(new_row))\n",
    "        \n",
    "        #Prepare for next loop\n",
    "        index = new_start_index\n",
    "        window_end_index = index + window['size']\n",
    "        new_start_index = window_end_index - window['stride']\n",
    "        \n",
    "    return pd.DataFrame(data, columns=new_row.keys())\n",
    "\n",
    "def train_without_outliers(normal_data, outlier_data, addition_normal_to_test):\n",
    "    normalizer = StandardScaler()\n",
    "    normalizer.set_output(transform='pandas')\n",
    "    \n",
    "    #Create new test data and drop it from the original data\n",
    "    additional_test_data = normal_data.sample(n=addition_normal_to_test)\n",
    "    normal_data = pd.concat([normal_data, additional_test_data]).drop_duplicates(keep=False)\n",
    "    \n",
    "    #Add class indication, combine, and shuffle\n",
    "    additional_test_data['class'] = 1\n",
    "    outlier_data['class'] = 0\n",
    "    test_data = pd.concat([additional_test_data, outlier_data])\n",
    "    test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    normal_data = normalizer.fit_transform(normal_data)\n",
    "    test_classes = test_data['class']\n",
    "    test_data = normalizer.transform(test_data.drop(['class'], axis=1))\n",
    "    \n",
    "    return normal_data, test_data, np.ones(len(normal_data)), test_classes\n",
    "#     return normal_data, test_data.drop(['class'], axis=1), np.ones(len(normal_data.values)), test_data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3776b",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model\n",
    "### Single Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAUSSIAN SINGLE PERSON OVERRIDE VARIABLES.\n",
    "#IF DESIRE TO USE, RUN THIS BEFORE THE BELOW CELLS AND DO NOT RUN THE GENERAL ONE IN BETWEEN\n",
    "subjects = random.choices(subject_directory_files, k = 1)\n",
    "subjects = [(subjects_path + x) if x.endswith('.pkl') else (subjects_path + (x + '.pkl')) for x in subjects]\n",
    "combine_subject_dataframes = True\n",
    "\n",
    "#Cutoff percentile at which scores are either classified normal or outlier points\n",
    "base_cutoff = 25\n",
    "\n",
    "#Up to which value to test best value for n_components, testing all integers in the range 1,n_limit\n",
    "n_limit = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2b5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validate_split(df, mix_data):\n",
    "    if not outlier_selection['between_subjects']:\n",
    "        numpy_data = df.to_numpy()\n",
    "        window_lengths = [np.linalg.norm(x) for x in numpy_data]\n",
    "        outlier_indexes = np.argpartition(window_lengths, (-1 * int(0.1*len(numpy_data))))[(-1 * int(0.1*len(numpy_data))):]\n",
    "        outliers = df.iloc[outlier_indexes]\n",
    "        data_without_outliers = pd.concat([df, outliers]).drop_duplicates(keep=False)\n",
    "    else:\n",
    "        outliers = mix_data[0]\n",
    "        data_without_outliers = df\n",
    "    \n",
    "    #train test split\n",
    "    X_train, X_test, y_train, y_test = train_without_outliers(data_without_outliers, outliers, int(len(df)*0.2))\n",
    "    \n",
    "    #validation test split\n",
    "    X_validate, X_test, y_validate, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "    \n",
    "    if outlier_selection['within_subject']:\n",
    "        X_train = pd.concat([X_train, mix_data[0]], ignore_index=True)\n",
    "        y_train = np.ones(len(X_train.values))\n",
    "    \n",
    "    return X_train, X_validate, X_test, y_train, y_validate, y_test\n",
    "\n",
    "def gmm_aic_score(estimator, X):\n",
    "    \"\"\"Callable to pass to GridSearchCV that will use the AIC score.\"\"\"\n",
    "    # Make it negative since GridSearchCV expects a score to maximize\n",
    "    return -estimator.aic(X)\n",
    "\n",
    "def find_best_params(X_validate):\n",
    "    param_grid = {\n",
    "        \"n_components\": range(1, n_limit),\n",
    "        \"covariance_type\": [\"spherical\", \"tied\", \"diag\", \"full\"],\n",
    "    }\n",
    "    grid_search = GridSearchCV(\n",
    "        GaussianMixture(), param_grid=param_grid, scoring=gmm_aic_score\n",
    "    )\n",
    "    grid_search.fit(X_validate)\n",
    "\n",
    "    return grid_search.best_params_['covariance_type'], grid_search.best_params_['n_components']\n",
    "\n",
    "def roc_curving(cov_type, n_com, X_train, X_validate, y_train, y_validate, print_curve=True):\n",
    "    #Fit on GMM and determine scores\n",
    "    gmm = GaussianMixture(covariance_type = cov_type, n_components = n_com)\n",
    "    gmm.fit(X_train.to_numpy())\n",
    "    scores = gmm.score_samples(X_validate.to_numpy())\n",
    "    \n",
    "    #Get ROC and AUC\n",
    "    auc = roc_auc_score(y_validate.to_numpy(), np.array(scores))\n",
    "    fpr, tpr, thresholds_sk = roc_curve(y_validate.to_numpy(), np.array(scores))\n",
    "    if print_curve:\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % auc)\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()\n",
    "\n",
    "    optimal_score_cutoff = sorted(list(zip(np.abs(np.subtract(tpr, fpr)), thresholds_sk)), key=lambda i: i[0], reverse=True)[0][1]\n",
    "    return optimal_score_cutoff, auc\n",
    "\n",
    "def prep_and_test(cov_type, n_com, X_train, X_test, y_train, y_test, thres = base_cutoff):\n",
    "    #Train and determine outliers\n",
    "    gmm = GaussianMixture(covariance_type = cov_type, n_components = n_com)\n",
    "    gmm.fit(X_train.to_numpy())\n",
    "    scores = gmm.score_samples(X_test.to_numpy())\n",
    "#     pct_threshold = np.percentile(scores, thres)\n",
    "    predictions = pd.Series(scores).apply(lambda x: 0 if x < thres else 1)\n",
    "    TP = [1 for x, y in zip(predictions, y_test.tolist()) if x == 0 and y == 0]\n",
    "    FP = [1 for x, y in zip(predictions, y_test.tolist()) if x == 0 and y == 1]\n",
    "    TN = [1 for x, y in zip(predictions, y_test.tolist()) if x == 1 and y == 1]\n",
    "    FN = [1 for x, y in zip(predictions, y_test.tolist()) if x == 1 and y == 0]\n",
    "    return len(TP), len(FP), len(TN), len(FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9e978a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subject_window, mix_data = sliding_window_creation()\n",
    "\n",
    "printing_section = subject_window.loc[0:10].copy()\n",
    "display(printing_section.style.set_caption(\"Initial 10 windows of subject\"))\n",
    "print(f\"Number of rows: {len(subject_window.values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd78e8d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test = train_test_validate_split(subject_window, mix_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbde1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_type, n_com = find_best_params(X_validate)\n",
    "print(f\"Found best covariance type: {cov_type} and number of components: {n_com}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a52f0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimal_cutoff = roc_curving(cov_type, n_com, X_train, X_validate, y_train, y_validate)\n",
    "# print(f\"Default cutoff provided: {base_cutoff}\")\n",
    "print(f\"Cutoff from ROC curve: {optimal_cutoff}\")\n",
    "\n",
    "# TP, FP, TN, FN = prep_and_test(X_train, X_test, y_train, y_test)\n",
    "# default_acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "TP, FP, TN, FN = prep_and_test(cov_type, n_com, X_train, X_test, y_train, y_test, optimal_cutoff)\n",
    "roc_acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "# print(f\"Default accuracy: {default_acc}\")\n",
    "print(f\"ROC accuracy: {roc_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab1d63",
   "metadata": {},
   "source": [
    "### Multiple Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda99dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAUSSIAN MULTIPLE PERSONS OVERRIDE VARIABLES.\n",
    "#IF DESIRE TO USE, RUN THIS BEFORE THE BELOW CELLS AND DO NOT RUN THE GENERAL ONE IN BETWEEN\n",
    "\n",
    "subjects = random.sample(subject_directory_files, 6)\n",
    "subjects = [(subjects_path + x) if x.endswith('.pkl') else (subjects_path + (x + '.pkl')) for x in subjects]\n",
    "\n",
    "combine_subject_dataframes = False\n",
    "\n",
    "#Cutoff percentile at which scores are either classified normal or outlier points\n",
    "base_cutoff = 33\n",
    "\n",
    "#Up to which value to test best value for n_components, testing all integers in the range 1,n_limit\n",
    "n_limit = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b44a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train_test_data(dfs, mix_data):\n",
    "    #Prep DataFrames for the GaussianMixture function and determine outliers\n",
    "    if not outlier_selection['between_group_and_individual']:\n",
    "        numpy_frames = [df.to_numpy() for df in dfs]\n",
    "        all_outliers = []\n",
    "        all_normal_data = []\n",
    "        for df, numpy_data in zip(dfs, numpy_frames):\n",
    "            window_lengths = [np.linalg.norm(x) for x in numpy_data]\n",
    "            outlier_indexes = np.argpartition(window_lengths, (-1 * int(0.1*len(numpy_data))))[(-1 * int(0.1*len(numpy_data))):]\n",
    "            outliers = df.iloc[outlier_indexes]\n",
    "            all_outliers.append(outliers)\n",
    "            data_without_outliers = pd.concat([df, outliers]).drop_duplicates(keep=False)\n",
    "            all_normal_data.append(data_without_outliers)\n",
    "    else:\n",
    "        all_outliers = [pd.concat(mix_data, ignore_index=True)]\n",
    "        all_normal_data = [pd.concat(dfs, ignore_index=True)]\n",
    "    \n",
    "    #Create train batches from x number of normal windows of every subject, and a test set for testing\n",
    "    x_train_data = []\n",
    "    x_test_data = []\n",
    "    x_validate_data = []\n",
    "    y_validate_data = []\n",
    "    y_train_data = []\n",
    "    y_test_data = []\n",
    "    for data_without_outliers, outliers in zip(all_normal_data, all_outliers):\n",
    "        X_train, X_test, y_train, y_test = train_without_outliers(data_without_outliers, outliers, int(len(outliers)*2))\n",
    "        \n",
    "        #validation test split\n",
    "        X_validate, X_test, y_validate, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "        \n",
    "        x_train_data.append(X_train.values.tolist())\n",
    "        x_test_data.append(X_test.values.tolist())\n",
    "        x_validate_data.append(X_validate.values.tolist())\n",
    "        y_validate_data.append(y_validate.tolist())\n",
    "        y_train_data.append(y_train)\n",
    "        y_test_data.append(y_test.tolist())\n",
    "    \n",
    "    if outlier_selection['within_group']:\n",
    "        X_train = pd.concat([X_train, outliers], ignore_index=True)\n",
    "        y_train = np.ones(len(X_train.values))\n",
    "    \n",
    "    X_train = list(itertools.chain.from_iterable(x_train_data))\n",
    "    X_test = list(itertools.chain.from_iterable(x_test_data))\n",
    "    X_validate = list(itertools.chain.from_iterable(x_validate_data))\n",
    "    y_validate = list(itertools.chain.from_iterable(y_validate_data))\n",
    "    y_train = list(itertools.chain.from_iterable(y_train_data))\n",
    "    y_test = list(itertools.chain.from_iterable(y_test_data))\n",
    "    \n",
    "    return np.array(X_train), np.array(X_validate), np.array(X_test), y_train, y_validate, y_test\n",
    "\n",
    "\n",
    "def roc_curve_multiple(cov_type, n_com, X_train, X_validate, y_train, y_validate, print_curve=True):\n",
    "    gmm = GaussianMixture(covariance_type = cov_type, n_components = n_com)\n",
    "    gmm.fit(X_train)\n",
    "    scores = gmm.score_samples(X_validate)\n",
    "    \n",
    "    #Get ROC and AUC\n",
    "    auc = roc_auc_score(y_validate, np.array(scores))\n",
    "    fpr, tpr, thresholds_sk = roc_curve(y_validate, np.array(scores))\n",
    "    if print_curve:\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % auc)\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()\n",
    "\n",
    "    optimal_score_cutoff = sorted(list(zip(np.abs(np.subtract(tpr, fpr)), thresholds_sk)), key=lambda i: i[0], reverse=True)[0][1]\n",
    "    return optimal_score_cutoff\n",
    "\n",
    "\n",
    "def train_and_test_multiple(cov_type, n_com, X_train, X_test, y_train, y_test, thres = base_cutoff):   \n",
    "    #Train and determine outliers\n",
    "    gmm = GaussianMixture(covariance_type = cov_type, n_components = n_com)\n",
    "    gmm.fit(X_train)\n",
    "    scores = gmm.score_samples(X_test)\n",
    "#     pct_threshold = np.percentile(scores, thres)\n",
    "    predictions = pd.Series(scores).apply(lambda x: 0 if x < thres else 1)\n",
    "    TP = [1 for x, y in zip(predictions, y_test) if x == 0 and y == 0]\n",
    "    FP = [1 for x, y in zip(predictions, y_test) if x == 0 and y == 1]\n",
    "    TN = [1 for x, y in zip(predictions, y_test) if x == 1 and y == 1]\n",
    "    FN = [1 for x, y in zip(predictions, y_test) if x == 1 and y == 0]\n",
    "    return len(TP), len(FP), len(TN), len(FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_window, mix_data = sliding_window_creation()\n",
    "print(\"Preprocessed data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f26d8b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test = prep_train_test_data(subjects_window, mix_data)\n",
    "print(\"Prepped train and test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_type, n_com = find_best_params(X_validate)\n",
    "print(f\"Found best covariance type: {cov_type} and number of components: {n_com}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f37f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimal_cutoff = roc_curve_multiple(cov_type, n_com, X_train, X_validate, y_train, y_validate)\n",
    "# print(f\"Default cutoff provided: {base_cutoff}\")\n",
    "print(f\"Cutoff from ROC curve: {optimal_cutoff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP, FP, TN, FN = train_and_test_multiple(X_train, X_test, y_train, y_test)\n",
    "# default_acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "TP, FP, TN, FN = train_and_test_multiple(cov_type, n_com, X_train, X_test, y_train, y_test, optimal_cutoff)\n",
    "roc_acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "# print(f\"Default outlier accuracy: {default_acc}\")\n",
    "print(f\"ROC outlier accuracy: {roc_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ddc9b3",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "### Single Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cba6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBSCAN SINGLE OVERRIDE VARIABLES.\n",
    "#IF DESIRE TO USE, RUN THIS BEFORE THE BELOW CELLS AND DO NOT RUN THE GENERAL ONE IN BETWEEN\n",
    "\n",
    "subjects = random.choices(subject_directory_files, k = 1)\n",
    "subjects = [(subjects_path + x) if x.endswith('.pkl') else (subjects_path + (x + '.pkl')) for x in subjects]\n",
    "combine_subject_dataframes = True\n",
    "\n",
    "feature_count = 0\n",
    "for value in features.values():\n",
    "    if type(value) is bool:\n",
    "        if value:\n",
    "            feature_count = feature_count + 1\n",
    "    if type(value) is list:\n",
    "        feature_count = feature_count + len(value)\n",
    "if data_sel['hr'] and data_sel['steps']:\n",
    "    feature_count = feature_count * 2\n",
    "\n",
    "minPts = 2*feature_count #Sander et al., 1998\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, mixing_data = sliding_window_creation()\n",
    "mixing_data = mixing_data[0]\n",
    "y_true=[]\n",
    "if outlier_selection['within_subject']:\n",
    "    numpy_data = df.to_numpy()\n",
    "    window_lengths = [np.linalg.norm(x) for x in numpy_data]\n",
    "    outlier_indexes = np.argpartition(window_lengths, (-1 * int(0.1*len(numpy_data))))[(-1 * int(0.1*len(numpy_data))):]\n",
    "    y_true = np.ones(len(numpy_data))\n",
    "    y_true[outlier_indexes] = 0\n",
    "    df['class'] = y_true\n",
    "    mixing_data['class'] = np.ones(len(mixing_data.values))\n",
    "    df = pd.concat([df,mixing_data], ignore_index=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True) #shuffle df\n",
    "    y_true = df['class'].tolist()\n",
    "    df = df.drop(['class'], axis=1)\n",
    "else:\n",
    "    df['class'] = np.ones(len(df.values))\n",
    "    mixing_data['class'] = np.zeros(len(mixing_data.values))\n",
    "    df = pd.concat([df,mixing_data], ignore_index=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True) #shuffle df\n",
    "    y_true = df['class'].tolist()\n",
    "    df = df.drop(['class'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_epsilon(df, minPts):\n",
    "    \"\"\"Find best epsilon using the elbow curve of K-NN distances and its point of maximum curviture\"\"\"\n",
    "    neighbors = NearestNeighbors(n_neighbors=minPts)\n",
    "    neighbors_fit = neighbors.fit(df)\n",
    "    distances, indices = neighbors_fit.kneighbors(df)\n",
    "\n",
    "    distances = np.sort(distances, axis=0)\n",
    "    distances = distances[:,1]\n",
    "\n",
    "    coords = np.column_stack((range(0,len(distances)), distances))\n",
    "    rotor = Rotor()\n",
    "    rotor.fit_rotate(coords)\n",
    "    elbow_index = rotor.get_elbow_index()\n",
    "    epsilon = coords[elbow_index][1]\n",
    "\n",
    "    return epsilon\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d240800",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = find_epsilon(df, minPts)\n",
    "\n",
    "dbscan=DBSCAN(eps=epsilon, min_samples=minPts)\n",
    "predictions = dbscan.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7659ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_predictions = [0 if x == -1 else 1 for x in predictions]\n",
    "TP = [1 for x, y in zip(cleaned_predictions, y_true) if x == 0 and y == 0]\n",
    "FP = [1 for x, y in zip(cleaned_predictions, y_true) if x == 0 and y == 1]\n",
    "TN = [1 for x, y in zip(cleaned_predictions, y_true) if x == 1 and y == 1]\n",
    "FN = [1 for x, y in zip(cleaned_predictions, y_true) if x == 1 and y == 0]\n",
    "print(epsilon)\n",
    "acc = (len(TP) + len(TN)) / (len(TP) + len(FP) + len(TN) + len(FN))\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "ari = adjusted_rand_score(y_true, cleaned_predictions)\n",
    "print(f\"Adjusted Rand Index: {ari}\")\n",
    "\n",
    "from sklearn.metrics import rand_score\n",
    "ari = rand_score(y_true, cleaned_predictions)\n",
    "print(f\"Rand Index: {ari}\")\n",
    "\n",
    "from sklearn import metrics\n",
    "ss = metrics.silhouette_score(df, y_true)\n",
    "print(f\"Silhouette Score: {ss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb4e5a8",
   "metadata": {},
   "source": [
    "### Multiple Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0fbc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBSCAN MULTIPLE PERSONS OVERRIDE VARIABLES.\n",
    "#IF DESIRE TO USE, RUN THIS BEFORE THE BELOW CELLS AND DO NOT RUN THE GENERAL ONE IN BETWEEN\n",
    "\n",
    "subjects = random.sample(subject_directory_files, 6)\n",
    "subjects = [(subjects_path + x) if x.endswith('.pkl') else (subjects_path + (x + '.pkl')) for x in subjects]\n",
    "\n",
    "combine_subject_dataframes = False\n",
    "\n",
    "feature_count = 0\n",
    "for value in features.values():\n",
    "    if type(value) is bool:\n",
    "        if value:\n",
    "            feature_count = feature_count + 1\n",
    "    if type(value) is list:\n",
    "        feature_count = feature_count + len(value)\n",
    "if data_sel['hr'] and data_sel['steps']:\n",
    "    feature_count = feature_count * 2\n",
    "    \n",
    "minPts = 2*feature_count #Sander et al., 1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, mixing_data = sliding_window_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "df = None\n",
    "if outlier_selection['within_group']:\n",
    "    y_trues = []\n",
    "    new_dfs = []\n",
    "    for df in dfs:\n",
    "        numpy_data = df.to_numpy()\n",
    "        window_lengths = [np.linalg.norm(x) for x in numpy_data]\n",
    "        outlier_indexes = np.argpartition(window_lengths, (-1 * int(0.1*len(numpy_data))))[(-1 * int(0.1*len(numpy_data))):]\n",
    "        y_true = np.zeros(len(numpy_data))\n",
    "        y_true[outlier_indexes] = 1\n",
    "        df['class'] = y_true\n",
    "        new_dfs.append(df)\n",
    "\n",
    "    df = pd.concat(new_dfs, ignore_index=True)\n",
    "    y_true = df['class'].tolist()\n",
    "    df = df.drop(['class'], axis=1)\n",
    "else:\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df['class'] = np.ones(len(df.values))\n",
    "    mix = pd.concat(mixing_data, ignore_index=True)\n",
    "    mix['class'] = np.zeros(len(mix.values))\n",
    "    df = pd.concat([df,mix], ignore_index=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True) #shuffle df\n",
    "    y_true = df['class'].tolist()\n",
    "    df = df.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_epsilon(df, minPts):\n",
    "    \"\"\"Find best epsilon using the elbow curve of K-NN distances and its point of maximum curviture\"\"\"\n",
    "#     results = []\n",
    "#     for df in dfs:\n",
    "    neighbors = NearestNeighbors(n_neighbors=minPts)\n",
    "    neighbors_fit = neighbors.fit(df)\n",
    "    distances, indices = neighbors_fit.kneighbors(df)\n",
    "\n",
    "    distances = np.sort(distances, axis=0)\n",
    "    distances = distances[:,1]\n",
    "    if outlier_selection['within_group']:\n",
    "        distances = (distances - np.mean(distances))/np.std(distances)\n",
    "\n",
    "    coords = np.column_stack((range(0,len(distances)), distances))\n",
    "    rotor = Rotor()\n",
    "    rotor.fit_rotate(coords)\n",
    "    elbow_index = rotor.get_elbow_index()\n",
    "    epsilon = coords[elbow_index][1]\n",
    "#         results.append(epsilon)\n",
    "#     print(results)\n",
    "    return epsilon\n",
    "#     return np.median(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83549972",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = find_epsilon(df, minPts)\n",
    "print(f\"epsilon: {epsilon}\")\n",
    "dbscan=DBSCAN(eps=epsilon, min_samples=minPts)\n",
    "predictions = dbscan.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fcc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_predictions = [0 if x == -1 else 1 for x in predictions]\n",
    "TP = [1 for x, y in zip(cleaned_predictions, y_true) if x == 0 and y == 0]\n",
    "FP = [1 for x, y in zip(cleaned_predictions, y_true) if x == 0 and y == 1]\n",
    "TN = [1 for x, y in zip(cleaned_predictions, y_true) if x == 1 and y == 1]\n",
    "FN = [1 for x, y in zip(cleaned_predictions, y_true) if x == 1 and y == 0]\n",
    "\n",
    "acc = (len(TP) + len(TN)) / (len(TP) + len(FP) + len(TN) + len(FN))\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "ari = adjusted_rand_score(y_true, cleaned_predictions)\n",
    "print(f\"Adjusted Rand Index: {ari}\")\n",
    "\n",
    "from sklearn.metrics import rand_score\n",
    "ari = rand_score(y_true, cleaned_predictions)\n",
    "print(f\"Rand Index: {ari}\")\n",
    "\n",
    "from sklearn import metrics\n",
    "ss = metrics.silhouette_score(df, y_true)\n",
    "print(f\"Silhouette Score: {ss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69451ded",
   "metadata": {},
   "source": [
    "## Bayesian Outlier Detection\n",
    "### Single Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ee0e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOD SINGLE PERSON OVERRIDE VARIABLES.\n",
    "#IF DESIRE TO USE, RUN THIS BEFORE THE BELOW CELLS AND DO NOT RUN THE GENERAL ONE IN BETWEEN\n",
    "\n",
    "column_name = 'window_length'\n",
    "prior_mean = None\n",
    "prior_std = None\n",
    "\n",
    "threshold = 0.2\n",
    "\n",
    "subjects = random.choices(subject_directory_files, k = 1)\n",
    "subjects = [(subjects_path + x) if x.endswith('.pkl') else (subjects_path + (x + '.pkl')) for x in subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46209cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_outlier(data_frame):\n",
    "    column_data = data_frame[column_name].values\n",
    "    \n",
    "    # Compute the sample mean and sample standard deviation\n",
    "    sample_mean = np.mean(column_data)\n",
    "    sample_std = np.std(column_data)\n",
    "    \n",
    "    # Compute the posterior mean and posterior standard deviation\n",
    "    posterior_precision = 1.0 / (1.0 / prior_std**2 + len(column_data) / sample_std**2)\n",
    "    posterior_mean = posterior_precision * (prior_mean / prior_std**2 + np.sum(column_data) / sample_std**2)\n",
    "    posterior_std = np.sqrt(1.0 / posterior_precision)\n",
    "    \n",
    "    # Compute the outlier probability for each data point\n",
    "    outlier_probs = np.exp(-0.5 * ((column_data - posterior_mean) / posterior_std)**2)\n",
    "    \n",
    "    # Determine the outliers based on the threshold\n",
    "    outliers = data_frame[outlier_probs < threshold]\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93062ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_windows = sliding_window_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dd7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = subject_windows.to_numpy()\n",
    "window_lengths = [np.linalg.norm(x) for x in numpy_data]\n",
    "subject_windows['window_length'] = pd.Series(window_lengths)\n",
    "outlier_indexes = np.argpartition(window_lengths, (-1 * int(0.1*len(numpy_data))))[(-1 * int(0.1*len(numpy_data))):]\n",
    "outliers = subject_windows.iloc[outlier_indexes]\n",
    "data_without_outliers = pd.concat([subject_windows, outliers]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf0f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_mean = np.mean(data_without_outliers['window_length'])\n",
    "prior_std = np.std(data_without_outliers['window_length'])\n",
    "\n",
    "predicted_outliers = bayesian_outlier(subject_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f40a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_np = outliers.to_numpy()\n",
    "negative_np = data_without_outliers.to_numpy()\n",
    "predict_np = predicted_outliers.to_numpy()\n",
    "neg_predict_np = (pd.concat([subject_windows, predicted_outliers]).drop_duplicates(keep=False)).to_numpy()\n",
    "TP = [1 for x in predict_np if any(np.equal(outliers_np,x).all(1))]\n",
    "FP = [1 for x in predict_np if not any(np.equal(outliers_np,x).all(1))]\n",
    "TN = [1 for x in neg_predict_np if any(np.equal(negative_np,x).all(1))]\n",
    "FN = [1 for x in neg_predict_np if not any(np.equal(negative_np,x).all(1))]        \n",
    "\n",
    "acc = (len(TP) + len(TN)) / (len(TP) + len(FP) + len(TN) + len(FN))\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35836147",
   "metadata": {},
   "source": [
    "### Multiple Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b97f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOD MULTIPLE PERSONS OVERRIDE VARIABLES.\n",
    "#IF DESIRE TO USE, RUN THIS BEFORE THE BELOW CELLS AND DO NOT RUN THE GENERAL ONE IN BETWEEN\n",
    "\n",
    "column_name = 'window_length'\n",
    "prior_mean = None\n",
    "prior_std = None\n",
    "\n",
    "threshold = 0.2\n",
    "\n",
    "subjects = random.sample(subject_directory_files, 6)\n",
    "subjects = [(subjects_path + x) if x.endswith('.pkl') else (subjects_path + (x + '.pkl')) for x in subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48cef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_outlier(data_frame):\n",
    "    column_data = data_frame[column_name].values\n",
    "    \n",
    "    # Compute the sample mean and sample standard deviation\n",
    "    sample_mean = np.mean(column_data)\n",
    "    sample_std = np.std(column_data)\n",
    "    \n",
    "    # Compute the posterior mean and posterior standard deviation\n",
    "    posterior_precision = 1.0 / (1.0 / prior_std**2 + len(column_data) / sample_std**2)\n",
    "    posterior_mean = posterior_precision * (prior_mean / prior_std**2 + np.sum(column_data) / sample_std**2)\n",
    "    posterior_std = np.sqrt(1.0 / posterior_precision)\n",
    "    \n",
    "    # Compute the outlier probability for each data point\n",
    "    outlier_probs = np.exp(-0.5 * ((column_data - posterior_mean) / posterior_std)**2)\n",
    "    \n",
    "    # Determine the outliers based on the threshold\n",
    "    outliers = data_frame[outlier_probs < threshold]\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_windows = sliding_window_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = subject_windows.to_numpy()\n",
    "window_lengths = [np.linalg.norm(x) for x in numpy_data]\n",
    "subject_windows['window_length'] = pd.Series(window_lengths)\n",
    "outlier_indexes = np.argpartition(window_lengths, (-1 * int(0.1*len(numpy_data))))[(-1 * int(0.1*len(numpy_data))):]\n",
    "outliers = subject_windows.iloc[outlier_indexes]\n",
    "data_without_outliers = pd.concat([subject_windows, outliers]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_mean = np.mean(data_without_outliers['window_length'])\n",
    "prior_std = np.std(data_without_outliers['window_length'])\n",
    "\n",
    "predicted_outliers = bayesian_outlier(subject_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e09831",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_np = outliers.to_numpy()\n",
    "negative_np = data_without_outliers.to_numpy()\n",
    "predict_np = predicted_outliers.to_numpy()\n",
    "neg_predict_np = (pd.concat([subject_windows, predicted_outliers]).drop_duplicates(keep=False)).to_numpy()\n",
    "TP = [1 for x in predict_np if any(np.equal(outliers_np,x).all(1))]\n",
    "FP = [1 for x in predict_np if not any(np.equal(outliers_np,x).all(1))]\n",
    "TN = [1 for x in neg_predict_np if any(np.equal(negative_np,x).all(1))]\n",
    "FN = [1 for x in neg_predict_np if not any(np.equal(negative_np,x).all(1))]        \n",
    "\n",
    "acc = (len(TP) + len(TN)) / (len(TP) + len(FP) + len(TN) + len(FN))\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
